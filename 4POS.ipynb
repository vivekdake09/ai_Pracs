{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022b221d-c946-46af-9a62-ce47216d36fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name - Vivek Dake \n",
    "Dept.  -TE[IT]\n",
    "Roll No - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0ebdd0d-7704-4f93-9771-ada0b64634d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, FreqDist, pos_tag\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0eb9c0e7-71d3-43f6-a195-34d7303a01d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vivek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vivek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\vivek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e65b44f6-d66f-40d0-a112-dc51f7e56361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_tokenization(text):\n",
    "    return word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b360b3f7-7404-42c6-ac62-17baea68ffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_frequency(tokens):\n",
    "    return FreqDist(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce31c361-8a30-45ff-aab5-005951549e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [word for word in tokens if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08f93328-ac22-4711-9739-faf90291fca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_tagging(tokens):\n",
    "    return pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7517eb31-3ec9-4055-a5a2-cf9b75c148cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a sentence or a paragraph:  Hello Myself Vivek Dake from IT Dept\n",
      "Select operation (a. Tokenization, b. Word Frequency, c. Remove Stop Words, d. POS Tagging):  a\n"
     ]
    }
   ],
   "source": [
    "text = input(\"Enter a sentence or a paragraph: \")\n",
    "operation = input(\"Select operation (a. Tokenization, b. Word Frequency, c. Remove Stop Words, d. POS Tagging): \").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0421a1b5-f3cd-4def-a5e9-3558c994d963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Hello', 'Myself', 'Vivek', 'Dake', 'from', 'IT', 'Dept']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if operation == 'a':\n",
    "        tokens = text_tokenization(text)\n",
    "        print(\"Tokens:\", tokens)\n",
    "    elif operation == 'b':\n",
    "        tokens = text_tokenization(text)\n",
    "        word_frequency = count_word_frequency(tokens)\n",
    "        print(\"Word Frequency:\", dict(word_frequency))\n",
    "    elif operation == 'c':\n",
    "        tokens = text_tokenization(text)\n",
    "        tokens_without_stopwords = remove_stop_words(tokens)\n",
    "        print(\"Tokens without Stop Words:\", tokens_without_stopwords)\n",
    "    elif operation == 'd':\n",
    "        tokens = text_tokenization(text)\n",
    "        pos_tags = pos_tagging(tokens)\n",
    "        print(\"POS Tags:\", pos_tags)\n",
    "    else:\n",
    "        print(\"Invalid operation. Please select a, b, c, or d.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "433403cd-3394-4fee-8d09-24e685afd7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select operation (a. Tokenization, b. Word Frequency, c. Remove Stop Words, d. POS Tagging):  a\n"
     ]
    }
   ],
   "source": [
    "operation = input(\"Select operation (a. Tokenization, b. Word Frequency, c. Remove Stop Words, d. POS Tagging): \").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fd86e4d1-5da7-4fce-95b1-2348811a1bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select operation (a. Tokenization, b. Word Frequency, c. Remove Stop Words, d. POS Tagging):  b\n"
     ]
    }
   ],
   "source": [
    "operation = input(\"Select operation (a. Tokenization, b. Word Frequency, c. Remove Stop Words, d. POS Tagging): \").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5e3415c5-ef32-41a3-9cbf-e1377b4c9da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequency: {'Hello': 1, 'Myself': 1, 'Vivek': 1, 'Dake': 1, 'from': 1, 'IT': 1, 'Dept': 1}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if operation == 'a':\n",
    "        tokens = text_tokenization(text)\n",
    "        print(\"Tokens:\", tokens)\n",
    "    elif operation == 'b':\n",
    "        tokens = text_tokenization(text)\n",
    "        word_frequency = count_word_frequency(tokens)\n",
    "        print(\"Word Frequency:\", dict(word_frequency))\n",
    "    elif operation == 'c':\n",
    "        tokens = text_tokenization(text)\n",
    "        tokens_without_stopwords = remove_stop_words(tokens)\n",
    "        print(\"Tokens without Stop Words:\", tokens_without_stopwords)\n",
    "    elif operation == 'd':\n",
    "        tokens = text_tokenization(text)\n",
    "        pos_tags = pos_tagging(tokens)\n",
    "        print(\"POS Tags:\", pos_tags)\n",
    "    else:\n",
    "        print(\"Invalid operation. Please select a, b, c, or d.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2c249d4-5067-4854-a2e4-c9768024b42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select operation (a. Tokenization, b. Word Frequency, c. Remove Stop Words, d. POS Tagging):  c\n"
     ]
    }
   ],
   "source": [
    "operation = input(\"Select operation (a. Tokenization, b. Word Frequency, c. Remove Stop Words, d. POS Tagging): \").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "93414ab7-a10c-49ea-b5d4-27b127dc99d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens without Stop Words: ['Hello', 'Vivek', 'Dake', 'Dept']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if operation == 'a':\n",
    "        tokens = text_tokenization(text)\n",
    "        print(\"Tokens:\", tokens)\n",
    "    elif operation == 'b':\n",
    "        tokens = text_tokenization(text)\n",
    "        word_frequency = count_word_frequency(tokens)\n",
    "        print(\"Word Frequency:\", dict(word_frequency))\n",
    "    elif operation == 'c':\n",
    "        tokens = text_tokenization(text)\n",
    "        tokens_without_stopwords = remove_stop_words(tokens)\n",
    "        print(\"Tokens without Stop Words:\", tokens_without_stopwords)\n",
    "    elif operation == 'd':\n",
    "        tokens = text_tokenization(text)\n",
    "        pos_tags = pos_tagging(tokens)\n",
    "        print(\"POS Tags:\", pos_tags)\n",
    "    else:\n",
    "        print(\"Invalid operation. Please select a, b, c, or d.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dcb0a22a-fd2f-4e8d-8fda-ada23ac02e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select operation (a. Tokenization, b. Word Frequency, c. Remove Stop Words, d. POS Tagging):  d\n"
     ]
    }
   ],
   "source": [
    "operation = input(\"Select operation (a. Tokenization, b. Word Frequency, c. Remove Stop Words, d. POS Tagging): \").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a09943d-1f50-420f-b61a-c55500708455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tags: [('Hello', 'NNP'), ('Myself', 'NNP'), ('Vivek', 'NNP'), ('Dake', 'NNP'), ('from', 'IN'), ('IT', 'NNP'), ('Dept', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if operation == 'a':\n",
    "        tokens = text_tokenization(text)\n",
    "        print(\"Tokens:\", tokens)\n",
    "    elif operation == 'b':\n",
    "        tokens = text_tokenization(text)\n",
    "        word_frequency = count_word_frequency(tokens)\n",
    "        print(\"Word Frequency:\", dict(word_frequency))\n",
    "    elif operation == 'c':\n",
    "        tokens = text_tokenization(text)\n",
    "        tokens_without_stopwords = remove_stop_words(tokens)\n",
    "        print(\"Tokens without Stop Words:\", tokens_without_stopwords)\n",
    "    elif operation == 'd':\n",
    "        tokens = text_tokenization(text)\n",
    "        pos_tags = pos_tagging(tokens)\n",
    "        print(\"POS Tags:\", pos_tags)\n",
    "    else:\n",
    "        print(\"Invalid operation. Please select a, b, c, or d.\")\n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdddb67a-15f6-41b9-bffd-ae35cc7594cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
